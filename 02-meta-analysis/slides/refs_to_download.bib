@ARTICLE{Shi2019-pj,
  title = {The trim-and-fill method for publication bias: practical guidelines
  and recommendations based on a large database of meta-analyses: practical
  guidelines and recommendations based on a large database of meta-analyses},
  author = {Shi, Linyu and Lin, Lifeng},
  journaltitle = {Medicine (Baltimore)},
  publisher = {Ovid Technologies (Wolters Kluwer Health)},
  volume = {98},
  issue = {23},
  pages = {e15987},
  date = {2019-06},
  doi = {10.1097/MD.0000000000015987},
  pmc = {PMC6571372},
  pmid = {31169736},
  issn = {0025-7974,1536-5964},
  abstract = {Publication bias is a type of systematic error when synthesizing
  evidence that cannot represent the underlying truth. Clinical studies with
  favorable results are more likely published and thus exaggerate the
  synthesized evidence in meta-analyses. The trim-and-fill method is a popular
  tool to detect and adjust for publication bias. Simulation studies have been
  performed to assess this method, but they may not fully represent realistic
  settings about publication bias. Based on real-world meta-analyses, this
  article provides practical guidelines and recommendations for using the
  trim-and-fill method. We used a worked illustrative example to demonstrate the
  idea of the trim-and-fill method, and we reviewed three estimators (R0, L0,
  and Q0) for imputing missing studies. A resampling method was proposed to
  calculate P values for all 3 estimators. We also summarized available
  meta-analysis software programs for implementing the trim-and-fill method.
  Moreover, we applied the method to 29,932 meta-analyses from the Cochrane
  Database of Systematic Reviews, and empirically evaluated its overall
  performance. We carefully explored potential issues occurred in our analysis.
  The estimators L0 and Q0 detected at least one missing study in more
  meta-analyses than R0, while Q0 often imputed more missing studies than L0.
  After adding imputed missing studies, the significance of heterogeneity and
  overall effect sizes changed in many meta-analyses. All estimators generally
  converged fast. However, L0 and Q0 failed to converge in a few meta-analyses
  that contained studies with identical effect sizes. Also, P values produced by
  different estimators could yield different conclusions of publication bias
  significance. Outliers and the pre-specified direction of missing studies
  could have influential impact on the trim-and-fill results. Meta-analysts are
  recommended to perform the trim-and-fill method with great caution when using
  meta-analysis software programs. Some default settings (e.g., the choice of
  estimators and the direction of missing studies) in the programs may not be
  optimal for a certain meta-analysis; they should be determined on a
  case-by-case basis. Sensitivity analyses are encouraged to examine effects of
  different estimators and outlying studies. Also, the trim-and-fill estimator
  should be routinely reported in meta-analyses, because the results depend
  highly on it.},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6571372/},
  language = {en}
}

@ARTICLE{Rosenthal1979-yx,
  title = {The file drawer problem and tolerance for null results},
  author = {Rosenthal, Robert},
  journaltitle = {Psychol. Bull.},
  publisher = {American Psychological Association (APA)},
  volume = {86},
  issue = {3},
  pages = {638-641},
  date = {1979-05},
  doi = {10.1037/0033-2909.86.3.638},
  issn = {0033-2909,1939-1455},
  url = {https://psycnet.apa.org/record/1979-27602-001},
  language = {en}
}

@ARTICLE{Citkowicz2017-ox,
  title = {A parsimonious weight function for modeling publication bias},
  author = {Citkowicz, Martyna and Vevea, Jack L},
  journaltitle = {Psychol. Methods},
  publisher = {psycnet.apa.org},
  volume = {22},
  issue = {1},
  pages = {28-41},
  date = {2017-03},
  doi = {10.1037/met0000119},
  pmid = {28252998},
  issn = {1082-989X,1939-1463},
  abstract = {Quantitative research literature is often biased because studies
  that fail to find a significant effect (or that demonstrate effects in an
  undesired or unexpected direction) are less likely to be published. This
  phenomenon, termed publication bias, can cause problems when researchers
  attempt to synthesize results using meta-analytic methods. Various techniques
  exist that attempt to estimate and correct meta-analyses for publication bias.
  However, there is no single method that can (a) account for continuous
  moderators by including them within the model, (b) allow for substantial data
  heterogeneity, (c) produce an adjusted mean effect size, (d) include a formal
  test for publication bias, and (e) allow for correction when only a small
  number of effects is included in the analysis. This article describes a method
  that we believe helps fill that gap. The model uses the beta density as a
  weight function that represents the selection process and provides adjusted
  parameter estimates that account for publication bias. Use of the beta density
  allows us to represent selection using fewer parameters than similar models so
  that the proposed model is suitable for meta-analyses that include relatively
  few studies. We explain the model and its rationale, illustrate its use with a
  real data set, and describe the results of a simulation study that shows the
  model's utility. (PsycINFO Database Record},
  url = {https://psycnet.apa.org/journals/met/22/1/28/},
  language = {en}
}

@MISC{Viechtbauer2021-od,
  title = {Selection models for publication bias in meta-analysis. Presentation
  at ESMARConf2021},
  author = {Viechtbauer, Wolfgang},
  publisher = {figshare},
  date = {2021-01-25},
  doi = {10.6084/M9.FIGSHARE.13637900.V1},
  abstract = {The non-replicability of certain findings in various disciplines
  has brought further attention to the problem that the published literature -
  which predominantly forms the evidence basis of research syntheses - may not
  be representative of all research that has been conducted on a particular
  topic. More specifically, concerns have been raised for a long time that
  statistically significant findings are overrepresented in the published
  literature, a phenomenon usually referred to as publication bias, which in
  turn can lead to biased conclusions. Various methods have been proposed in the
  meta-analytic literature for detecting the presence of publication bias,
  estimating its potential impact, and correcting for it. So-called selection
  models are among the most sophisticated methods for this purpose, as they
  attempt to directly model the selection process. If a particular selection
  model is an adequate approximation for the underlying selection process, then
  the model provides estimates of the parameters of interest (e.g., the average
  true effect and the amount of heterogeneity in the true effects) that are
  'corrected' for this selection process (i.e., they are estimates of the
  parameters in the population of studies before any selection has taken place).
  In this talk, I will briefly describe a variety of models for this purpose and
  illustrate their application with the metafor package in R.},
  url = {https://figshare.com/articles/conference_contribution/Selection_models_for_publication_bias_in_meta-analysis_Presentation_at_ESMARConf2021/13637900}
}

@ARTICLE{Dear2019-qc,
  title = {Do ‘watching eyes’ influence antisocial behavior? A systematic review
  \& meta-analysis},
  author = {Dear, Keith and Dutton, Kevin and Fox, Elaine},
  journaltitle = {Evol. Hum. Behav.},
  publisher = {Elsevier BV},
  volume = {40},
  issue = {3},
  pages = {269-280},
  date = {2019-05-01},
  doi = {10.1016/j.evolhumbehav.2019.01.006},
  issn = {1090-5138,1879-0607},
  abstract = {Eye cues have been shown to stimulate rapid, reflexive,
  unconscious processing and in many experimental settings to cue increased
  prosocial and decrea…},
  url = {http://dx.doi.org/10.1016/j.evolhumbehav.2019.01.006},
  urldate = {2023-09-05},
  language = {en}
}

@ARTICLE{Duval2000-ym,
  title = {Trim and fill: A simple funnel-plot-based method of testing and
  adjusting for publication bias in meta-analysis},
  author = {Duval, S and Tweedie, R},
  journaltitle = {Biometrics},
  publisher = {Wiley},
  volume = {56},
  issue = {2},
  pages = {455-463},
  date = {2000-06},
  doi = {10.1111/j.0006-341x.2000.00455.x},
  pmid = {10877304},
  issn = {0006-341X,1541-0420},
  abstract = {We study recently developed nonparametric methods for estimating
  the number of missing studies that might exist in a meta-analysis and the
  effect that these studies might have had on its outcome. These are simple
  rank-based data augmentation techniques, which formalize the use of funnel
  plots. We show that they provide effective and relatively powerful tests for
  evaluating the existence of such publication bias. After adjusting for missing
  studies, we find that the point estimate of the overall effect size is
  approximately correct and coverage of the effect size confidence intervals is
  substantially improved, in many cases recovering the nominal confidence levels
  entirely. We illustrate the trim and fill method on existing meta-analyses of
  studies in clinical trials and psychometrics.},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/j.0006-341X.2000.00455.x},
  keywords = {Meta-analysis},
  language = {en}
}

@MISC{Viechtbauer2010-xz,
  title = {Conducting meta-analyses in {R} with the {metafor} package},
  author = {Viechtbauer, Wolfgang},
  journaltitle = {Journal of Statistical Software},
  volume = {36},
  issue = {3},
  pages = {1-48},
  date = {2010},
  doi = {10.18637/jss.v036.i03},
  url = {https://doi.org/10.18637/jss.v036.i03},
  keywords = {Meta-analysis}
}

@MISC{Borenstein2009-mo,
  title = {Introduction to {Meta-Analysis}},
  author = {Borenstein, Michael and Hedges, Larry V and Higgins, Julian P T and
  Rothstein, Hannah R},
  date = {2009},
  doi = {10.1002/9780470743386},
  url = {http://dx.doi.org/10.1002/9780470743386},
  keywords = {MA Unconscious WM}
}

@ARTICLE{Higgins2002-fh,
  title = {Quantifying heterogeneity in a meta-analysis},
  author = {Higgins, Julian P T and Thompson, Simon G},
  journaltitle = {Stat. Med.},
  volume = {21},
  issue = {11},
  pages = {1539-1558},
  date = {2002-06-15},
  doi = {10.1002/sim.1186},
  pmid = {12111919},
  issn = {0277-6715},
  abstract = {The extent of heterogeneity in a meta-analysis partly determines
  the difficulty in drawing overall conclusions. This extent may be measured by
  estimating a between-study variance, but interpretation is then specific to a
  particular treatment effect metric. A test for the existence of heterogeneity
  exists, but depends on the number of studies in the meta-analysis. We develop
  measures of the impact of heterogeneity on a meta-analysis, from mathematical
  criteria, that are independent of the number of studies and the treatment
  effect metric. We derive and propose three suitable statistics: H is the
  square root of the chi2 heterogeneity statistic divided by its degrees of
  freedom; R is the ratio of the standard error of the underlying mean from a
  random effects meta-analysis to the standard error of a fixed effect
  meta-analytic estimate, and I2 is a transformation of (H) that describes the
  proportion of total variation in study estimates that is due to heterogeneity.
  We discuss interpretation, interval estimates and other properties of these
  measures and examine them in five example data sets showing different amounts
  of heterogeneity. We conclude that H and I2, which can usually be calculated
  for published meta-analyses, are particularly useful summaries of the impact
  of heterogeneity. One or both should be presented in published meta-analyses
  in preference to the test for heterogeneity.},
  url = {http://dx.doi.org/10.1002/sim.1186},
  language = {en}
}

@ARTICLE{Viechtbauer2005-zt,
  title = {Bias and efficiency of meta-analytic variance estimators in the
  random-effects model},
  author = {Viechtbauer, Wolfgang},
  journaltitle = {J. Educ. Behav. Stat.},
  publisher = {American Educational Research Association (AERA)},
  volume = {30},
  issue = {3},
  pages = {261-293},
  date = {2005-09},
  doi = {10.3102/10769986030003261},
  issn = {1076-9986,1935-1054},
  abstract = {The meta-analytic random effects model assumes that the
  variability in effect size estimates drawn from a set of studies can be
  decomposed into two parts: heterogeneity due to random population effects and
  sampling variance. In this context, the usual goal is to estimate the central
  tendency and the amount of heterogeneity in the population effect sizes. The
  amount of heterogeneity in a set of effect sizes has implications regarding
  the interpretation of the meta-analytic findings and often serves as an
  indicator for the presence of potential moderator variables. Five population
  heterogeneity estimators were compared in this article analytically and via
  Monte Carlo simulations with respect to their bias and efficiency.},
  url = {https://scholar.google.com/citations?view_op=view_citation&hl=en&user=J89RXJkAAAAJ&citation_for_view=J89RXJkAAAAJ:qjMakFHDy7sC},
  language = {en}
}

@ARTICLE{Guan2016-kn,
  title = {A Bayesian approach to mitigation of publication bias},
  author = {Guan, Maime and Vandekerckhove, Joachim},
  journaltitle = {Psychon. Bull. Rev.},
  volume = {23},
  issue = {1},
  pages = {74-86},
  date = {2016-02},
  doi = {10.3758/s13423-015-0868-6},
  pmid = {26126776},
  issn = {1069-9384,1531-5320},
  abstract = {The reliability of published research findings in psychology has
  been a topic of rising concern. Publication bias, or treating positive
  findings differently from negative findings, is a contributing factor to this
  "crisis of confidence," in that it likely inflates the number of
  false-positive effects in the literature. We demonstrate a Bayesian model
  averaging approach that takes into account the possibility of publication bias
  and allows for a better estimate of true underlying effect size. Accounting
  for the possibility of bias leads to a more conservative interpretation of
  published studies as well as meta-analyses. We provide mathematical details of
  the method and examples.},
  url = {http://dx.doi.org/10.3758/s13423-015-0868-6},
  keywords = {Bayesian inference and parameter estimation; Bayesian statistics;
  Math modeling and model selection; Meta-analysis;Bayesian Statistics},
  language = {en}
}

